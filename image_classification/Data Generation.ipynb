{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA EXTRACTION FROM THE ORIGINAL FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "#!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "#!wget http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/Single_shot_detector'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11815179343562343161\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 715128900066388826\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 5996905616586890750\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:1\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 17021470034951504829\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:2\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 3634109189779882519\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:XLA_GPU:3\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12503219660809635503\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 199753728\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 10479900184149005965\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:1\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10852525671\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 13255602908523576493\n",
      "physical_device_desc: \"device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:2\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10852525671\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 3\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 17733684628612058399\n",
      "physical_device_desc: \"device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:41:00.0, compute capability: 6.1\"\n",
      ", name: \"/device:GPU:3\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10016944948\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "    link {\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 1\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "    link {\n",
      "      device_id: 2\n",
      "      type: \"StreamExecutor\"\n",
      "      strength: 1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "incarnation: 4762238996683242391\n",
      "physical_device_desc: \"device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:42:00.0, compute capability: 6.1\"\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pwd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-4844e337a3c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSSD_VGG16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSDBoxEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/purva/Single_shot_detector/SSD_VGG16.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mpwd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pwd' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas\n",
    "import os\n",
    "import warnings\n",
    "import sklearn.utils\n",
    "from copy import deepcopy\n",
    "from PIL import Image\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from SSD_VGG16 import SSDBoxEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOC_2007_images_dir      = \"./VOC2007/JPEGImages/\"\n",
    "VOC_2007_test_images_dir = './VOC2007_Test/JPEGImages/'\n",
    "VOC_2012_images_dir      = './VOC2012/JPEGImages/'\n",
    "\n",
    "# The directories that contain the annotations.\n",
    "VOC_2007_annotations_dir      = './VOC2007/Annotations/'\n",
    "VOC_2007_test_annotations_dir = './VOC2007_Test/Annotations/'\n",
    "VOC_2012_annotations_dir      = './VOC2012/Annotations/'\n",
    "\n",
    "# The paths to the image sets.\n",
    "VOC_2007_train_image_set_filename    = './VOC2007/ImageSets/Main/train.txt'\n",
    "VOC_2012_train_image_set_filename    = './VOC2012/ImageSets/Main/train.txt'\n",
    "VOC_2007_val_image_set_filename      = './VOC2007/ImageSets/Main/val.txt'\n",
    "VOC_2012_val_image_set_filename      = './VOC2012/ImageSets/Main/val.txt'\n",
    "VOC_2007_trainval_image_set_filename = './VOC2007/ImageSets/Main/trainval.txt'\n",
    "VOC_2012_trainval_image_set_filename = './VOC2012/ImageSets/Main/trainval.txt'\n",
    "VOC_2007_test_image_set_filename     = './VOC2007_Test/ImageSets/Main/test.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/purva/Desktop/purva/Single_shot_detector'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes=['background',\n",
    "                       'aeroplane', 'bicycle', 'bird', 'boat',\n",
    "                       'bottle', 'bus', 'car', 'cat',\n",
    "                       'chair', 'cow', 'diningtable', 'dog',\n",
    "                       'horse', 'motorbike', 'person', 'pottedplant',\n",
    "                       'sheep', 'sofa', 'train', 'tvmonitor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_xml(images_dirs,\n",
    "              image_set_filenames,\n",
    "              annotations_dirs=[],\n",
    "              include_classes = 'all',\n",
    "              exclude_truncated=False,\n",
    "              exclude_difficult=False):\n",
    "\n",
    "    box_output_format=['class_id', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    filenames = []\n",
    "    image_ids = []\n",
    "    labels = []\n",
    "    for images_dir, image_set_filename, annotations_dir in zip(images_dirs, image_set_filenames, annotations_dirs):\n",
    "        # Read the image set file that so that we know all the IDs of all the images to be included in the dataset.\n",
    "        with open(image_set_filename) as f:\n",
    "            image_ids = [line.strip() for line in f] # Note: These are strings, not integers.\n",
    "            image_ids += image_ids\n",
    "\n",
    "        # Loop over all images in this dataset.\n",
    "        for image_id in image_ids:\n",
    "\n",
    "            filename = '{}'.format(image_id) + '.jpg'\n",
    "            filenames.append(os.path.join(images_dir, filename))\n",
    "\n",
    "            if not annotations_dir is None:\n",
    "                # Parse the XML file for this image.\n",
    "                with open(os.path.join(annotations_dir, image_id + '.xml')) as f:\n",
    "                    soup = BeautifulSoup(f, 'xml')\n",
    "\n",
    "                folder = soup.folder.text # In case we want to return the folder in addition to the image file name. Relevant for determining which dataset an image belongs to.\n",
    "                #filename = soup.filename.text\n",
    "\n",
    "                boxes = [] # We'll store all boxes for this image here\n",
    "                objects = soup.find_all('object') # Get a list of all objects in this image\n",
    "\n",
    "                # Parse the data for each object\n",
    "                for obj in objects:\n",
    "                    class_name = obj.find('name').text\n",
    "                    class_id = classes.index(class_name)\n",
    "                    # Check if this class is supposed to be included in the dataset\n",
    "                    \n",
    "                    pose = obj.pose.text\n",
    "                    truncated = int(obj.truncated.text)\n",
    "                    if exclude_truncated and (truncated == 1): continue\n",
    "                    difficult = int(obj.difficult.text)\n",
    "                    if exclude_difficult and (difficult == 1): continue\n",
    "                    xmin = int(obj.bndbox.xmin.text)\n",
    "                    ymin = int(obj.bndbox.ymin.text)\n",
    "                    xmax = int(obj.bndbox.xmax.text)\n",
    "                    ymax = int(obj.bndbox.ymax.text)\n",
    "                    item_dict = {'folder': folder,\n",
    "                                 'image_name': filename,\n",
    "                                 'image_id': image_id,\n",
    "                                 'class_name': class_name,\n",
    "                                 'class_id': class_id,\n",
    "                                 'pose': pose,\n",
    "                                 'truncated': truncated,\n",
    "                                 'difficult': difficult,\n",
    "                                 'xmin': xmin,\n",
    "                                 'ymin': ymin,\n",
    "                                 'xmax': xmax,\n",
    "                                 'ymax': ymax}\n",
    "                    box = []\n",
    "                    for item in box_output_format:\n",
    "                        box.append(item_dict[item])\n",
    "                    boxes.append(box)\n",
    "\n",
    "                labels.append(boxes)\n",
    "\n",
    "    return filenames, labels, image_ids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 259 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_data=parse_xml(images_dirs=[VOC_2007_images_dir,\n",
    "                                     VOC_2012_images_dir],\n",
    "                       \n",
    "                     image_set_filenames=[VOC_2007_trainval_image_set_filename,\n",
    "                                             VOC_2012_trainval_image_set_filename],\n",
    "                     \n",
    "                     annotations_dirs=[VOC_2007_annotations_dir,\n",
    "                                          VOC_2012_annotations_dir],\n",
    "                        \n",
    "                     \n",
    "                     exclude_truncated=False,\n",
    "                     \n",
    "                     exclude_difficult=False)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_data = parse_xml(images_dirs=[VOC_2007_test_images_dir],\n",
    "                     \n",
    "                     image_set_filenames=[VOC_2007_test_image_set_filename],\n",
    "                     \n",
    "                     annotations_dirs=[VOC_2007_test_annotations_dir],\n",
    "                      \n",
    "                      exclude_truncated=False,\n",
    "                     \n",
    "                      exclude_difficult=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-dbc19158bb1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "len(train_data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAVE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filenames_out=open(\"train_filenames.pickle\",'wb')\n",
    "pickle.dump(train_data[0],filenames_out)\n",
    "filenames_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "filenames_out=open(\"val_filenames.pickle\",'wb')\n",
    "pickle.dump(val_data[0],filenames_out)\n",
    "filenames_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_out=open(\"train_labels.pickle\",'wb')\n",
    "pickle.dump(train_data[1],labels_out)\n",
    "labels_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "labels_out=open(\"val_labels.pickle\",'wb')\n",
    "pickle.dump(val_data[1],labels_out)\n",
    "labels_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image_ids_out=open(\"train_image_ids.pickle\",'wb')\n",
    "pickle.dump(train_data[2],image_ids_out)\n",
    "image_ids_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image_ids_out=open(\"val_image_ids.pickle\",'wb')\n",
    "pickle.dump(val_data[2],image_ids_out)\n",
    "image_ids_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(image, horizontal=(0,40), vertical=(0,10)):\n",
    "   \n",
    "    rows,cols,ch = image.shape\n",
    "\n",
    "    x = np.random.randint(horizontal[0], horizontal[1]+1)\n",
    "    y = np.random.randint(vertical[0], vertical[1]+1)\n",
    "    x_shift = random.choice([-x, x])\n",
    "    y_shift = random.choice([-y, y])\n",
    "\n",
    "    M = np.float32([[1,0,x_shift],[0,1,y_shift]])\n",
    "    return cv2.warpAffine(image, M, (cols, rows)), x_shift, y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread(train_data[0][0])\n",
    "trans=translate(img)\n",
    "trans[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Translated IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(translate(img)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ORIGINAL IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip(image, orientation='horizontal'):\n",
    "    \n",
    "    if orientation == 'horizontal':\n",
    "        return cv2.flip(image, 1)\n",
    "    else:\n",
    "        return cv2.flip(image, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(val_data[0][123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(flip(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, min=0.9, max=1.1):\n",
    "    rows,cols,ch = image.shape\n",
    "    scale = np.random.uniform(min, max)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2), 0, scale)\n",
    "    return cv2.warpAffine(image, M, (cols, rows)), M, scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(val_data[0][111])\n",
    "print(\"Original Image:\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Scaled Image:\")\n",
    "plt.imshow(scale(img)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def brightness(image, min=0.5, max=2.0):\n",
    "    hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    random_br = np.random.uniform(min,max)\n",
    "    mask = hsv[:,:,2] * random_br > 255\n",
    "    v_channel = np.where(mask, 255, hsv[:,:,2] * random_br)\n",
    "    hsv[:,:,2] = v_channel\n",
    "    return cv2.cvtColor(hsv,cv2.COLOR_HSV2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image:\")\n",
    "img=cv2.imread(train_data[0][890])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Brightened Image:\")\n",
    "img=cv2.imread(train_data[0][890])\n",
    "plt.imshow(brightness(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram Equlaizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_eq(image):\n",
    "    image1 = np.copy(image)\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_RGB2HSV)\n",
    "    image1[:,:,2] = cv2.equalizeHist(image1[:,:,2])\n",
    "    image1 = cv2.cvtColor(image1, cv2.COLOR_HSV2RGB)\n",
    "    return image1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original Image:\")\n",
    "img=cv2.imread(train_data[0][1890])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Brightened Image:\")\n",
    "img=cv2.imread(train_data[0][1890])\n",
    "plt.imshow(histogram_eq(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
